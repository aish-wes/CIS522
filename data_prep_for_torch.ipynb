{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d57e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58c6eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check to see if the GPU is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca515a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up GPU device, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab87ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class for implementing Dataset object (needed for Dataloader)\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        sample = {'data':data, 'labels':label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3db247f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our data sets as numpy arrays (also reshape back to images)\n",
    "asl_data = np.load('asl_data.npy').reshape(-1, 36, 36, 3)\n",
    "asl_labels = np.load('asl_labels.npy')\n",
    "isl_data = np.load('isl_data.npy').reshape(-1, 36, 36, 3)\n",
    "isl_labels = np.load('isl_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "464fbaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "asl_train_data, asl_test_data, asl_train_labels, asl_test_labels = train_test_split(asl_data, asl_labels, test_size=0.2)\n",
    "isl_train_data, isl_test_data, isl_train_labels, isl_test_labels = train_test_split(isl_data, isl_labels, test_size=0.2)\n",
    "asl_data, asl_labels, isl_data, isl_labels = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c40ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy arrays to torch tensors and permute the dimensions for CNN processing (N, C, H, W)\n",
    "asl_train_data = torch.from_numpy(asl_train_data).permute(0, 3, 1, 2).float()\n",
    "asl_train_labels = torch.from_numpy(asl_train_labels).long()\n",
    "isl_train_data = torch.from_numpy(isl_train_data).permute(0, 3, 1, 2).float()\n",
    "isl_train_labels = torch.from_numpy(isl_train_labels).long()\n",
    "asl_test_data = torch.from_numpy(asl_test_data).permute(0, 3, 1, 2).float()\n",
    "asl_test_labels = torch.from_numpy(asl_test_labels).long()\n",
    "isl_test_data = torch.from_numpy(isl_test_data).permute(0, 3, 1, 2).float()\n",
    "isl_test_labels = torch.from_numpy(isl_test_labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cd28650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # our composer object for applying tranformations and augmentations (simply modify the list)\n",
    "# composer = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(p=0.25),\n",
    "#     transforms.RandomVerticalFlip(p=0.25),\n",
    "#     transforms.RandomRotation(15),\n",
    "#     transforms.ColorJitter()\n",
    "# ])\n",
    "# # pass the training image data through the composer and concatenate\n",
    "# asl_train_data = torch.cat((asl_train_data, composer(asl_train_data)))\n",
    "# isl_train_data = torch.cat((isl_train_data, composer(isl_train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90877e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataset objects for both the ASL and ISL data\n",
    "asl_train_dataset = Dataset(asl_train_data, asl_train_labels)\n",
    "isl_train_dataset = Dataset(isl_train_data, isl_train_labels)\n",
    "asl_test_dataset = Dataset(asl_test_data, asl_test_labels)\n",
    "isl_test_dataset = Dataset(isl_test_data, isl_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa407f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataloader objects for training\n",
    "asl_train_dataloader = DataLoader(asl_train_dataset, batch_size=64, shuffle=True)\n",
    "isl_train_dataloader = DataLoader(isl_train_dataset, batch_size=64, shuffle=True)\n",
    "asl_test_dataloader = DataLoader(asl_test_dataset, batch_size=64, shuffle=True)\n",
    "isl_test_dataloader = DataLoader(isl_test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e4b1c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(asl_train_dataloader):\n",
    "    if (i % 100 == 0):\n",
    "        data, labels = batch['data'], batch['labels']\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c095d30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n",
      "torch.Size([64, 3, 36, 36]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(isl_train_dataloader):\n",
    "    if (i % 100 == 0):\n",
    "        data, labels = batch['data'], batch['labels']\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd134125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.batchnorm = torch.nn.BatchNorm2d(256)\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "        self.linear1 = torch.nn.Linear(256*6*6, 1024)\n",
    "        self.linear2 = torch.nn.Linear(1024, 27)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.maxpool1(self.relu(self.conv1(x)))\n",
    "        out = self.maxpool2(self.relu(self.conv2(out)))\n",
    "        out = self.maxpool3(self.relu(self.conv3(out)))\n",
    "        out = self.batchnorm(out)\n",
    "        out = torch.flatten(out, start_dim=1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.sigmoid(self.linear1(out))\n",
    "        out = self. linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "545eee5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Done\n",
      "Epoch 1 Done\n",
      "Epoch 2 Done\n",
      "Epoch 3 Done\n",
      "Epoch 4 Done\n",
      "Epoch 5 Done\n",
      "Epoch 6 Done\n",
      "Epoch 7 Done\n",
      "Epoch 8 Done\n",
      "Epoch 9 Done\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "training_accuracy = []\n",
    "training_loss = []\n",
    "testing_accuracy = []\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_loss = 0\n",
    "    net.train()\n",
    "    for batch in asl_train_dataloader:\n",
    "        data, labels = batch['data'], batch['labels']\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = net(data)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "        total += labels.shape[0]\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    training_accuracy.append(correct/total)\n",
    "    training_loss.append(epoch_loss)\n",
    "    print(\"Epoch {} Done\".format(str(epoch)))\n",
    "    \n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in asl_test_dataloader:\n",
    "            data, labels = batch['data'], batch['labels']\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predictions = net(data)\n",
    "            _, predicted = torch.max(predictions, 1)\n",
    "            test_total += labels.shape[0]\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "        testing_accuracy.append(test_correct/test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1f6261d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8009365131220734,\n",
       " 0.9749226054355097,\n",
       " 0.9843499634417635,\n",
       " 0.9865590143277174,\n",
       " 0.9889547455702307,\n",
       " 0.9900592710132077,\n",
       " 0.992066084846222,\n",
       " 0.9922216518100216,\n",
       " 0.9918638477932826,\n",
       " 0.9944618160887354]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2de3dfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9668968950283119,\n",
       " 0.9888619252068944,\n",
       " 0.9914753282309751,\n",
       " 0.9589944620745442,\n",
       " 0.9922220148092838,\n",
       " 0.9974488208574451,\n",
       " 0.9963910148715077,\n",
       " 0.9953332088855703,\n",
       " 0.9977599402650738,\n",
       " 0.9990044178955884]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd1c903a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[652.6611473225057,\n",
       " 82.81278530228883,\n",
       " 51.571664814371616,\n",
       " 42.01046396745369,\n",
       " 33.28210420534015,\n",
       " 30.51154064614093,\n",
       " 24.616194724920206,\n",
       " 22.384505321795586,\n",
       " 25.08499616268091,\n",
       " 16.628041069736355]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef594e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
